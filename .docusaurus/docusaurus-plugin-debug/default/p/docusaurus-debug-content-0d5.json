{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/","tagsPath":"/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\Hackathon Project\\docusaurus_sidebar.js","contentPath":"D:\\Hackathon Project\\docs","docs":[{"id":"404","title":"Page Not Found","description":"The page you're looking for doesn't exist. Start from the beginning!","source":"@site/docs/404.md","sourceDirName":".","slug":"/404","permalink":"/404","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Page Not Found","description":"The page you're looking for doesn't exist. Start from the beginning!"}},{"id":"glossary","title":"Technical Glossary","description":"AI-Native Physical AI & Humanoid Robotics Textbook","source":"@site/docs/glossary.md","sourceDirName":".","slug":"/glossary","permalink":"/glossary","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Part 7 Overview","permalink":"/part-7/PART_7_overview"},"next":{"title":"RAG Index & Semantic Map","permalink":"/rag_index"}},{"id":"index","title":"Physical AI & Humanoid Robotics","description":"From Digital Intelligence to Embodied Autonomous Systems","source":"@site/docs/index.md","sourceDirName":".","slug":"/","permalink":"/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Physical AI & Humanoid Robotics","description":"From Digital Intelligence to Embodied Autonomous Systems"}},{"id":"introduction","title":"Book Introduction","description":"Overview and positioning of the AI-Native Physical AI & Humanoid Robotics textbook","source":"@site/docs/00_introduction.md","sourceDirName":".","slug":"/introduction","permalink":"/introduction","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"title":"Book Introduction","description":"Overview and positioning of the AI-Native Physical AI & Humanoid Robotics textbook","difficulty":"Beginner","category":"Introduction","keywords":["physical AI","robotics","humanoids","introduction","learning path","textbook"]},"sidebar":"textbookSidebar","next":{"title":"Part 1 Overview","permalink":"/part-1/PART_1_overview"}},{"id":"part-1/PART_1_overview","title":"PART 1 - Foundations of Physical AI","description":"Core concepts, principles, and systems that form the foundation for AI-driven physical systems","source":"@site/docs/part-1/PART_1_overview.md","sourceDirName":"part-1","slug":"/part-1/PART_1_overview","permalink":"/part-1/PART_1_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 1 - Foundations of Physical AI","description":"Core concepts, principles, and systems that form the foundation for AI-driven physical systems","difficulty":"Intermediate","category":"Part Overview","keywords":["physical AI","embodied intelligence","robotics fundamentals","sensor-actuator systems","sim-to-real"]},"sidebar":"textbookSidebar","previous":{"title":"Book Introduction","permalink":"/introduction"},"next":{"title":"Chapter 1: Physical AI Fundamentals","permalink":"/part-1/physical_ai_fundamentals"}},{"id":"part-1/physical_ai_fundamentals","title":"Chapter 1 - Physical AI Fundamentals","description":"Definition, scope, and positioning of Physical AI within the broader AI and robotics landscape. Explores embodied cognition and the fundamental differences from traditional software AI.","source":"@site/docs/part-1/01_physical_ai_fundamentals.md","sourceDirName":"part-1","slug":"/part-1/physical_ai_fundamentals","permalink":"/part-1/physical_ai_fundamentals","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Chapter 1 - Physical AI Fundamentals","description":"Definition, scope, and positioning of Physical AI within the broader AI and robotics landscape. Explores embodied cognition and the fundamental differences from traditional software AI.","difficulty":"Intermediate","category":"Part 1 - Foundations","keywords":["physical AI","embodied intelligence","artificial intelligence","robotics","hardware-software integration"]},"sidebar":"textbookSidebar","previous":{"title":"Part 1 Overview","permalink":"/part-1/PART_1_overview"},"next":{"title":"Chapter 2: Robotics Systems & Embodied Intelligence","permalink":"/part-1/robotics_systems"}},{"id":"part-1/robotics_systems","title":"Chapter 2 - Robotics Systems & Embodied Intelligence","description":"Hardware fundamentals, system architecture, control loops, and the design principles underlying modern robotics systems. Covers sensors, actuators, kinematics, and integrated system design.","source":"@site/docs/part-1/02_robotics_systems.md","sourceDirName":"part-1","slug":"/part-1/robotics_systems","permalink":"/part-1/robotics_systems","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Chapter 2 - Robotics Systems & Embodied Intelligence","description":"Hardware fundamentals, system architecture, control loops, and the design principles underlying modern robotics systems. Covers sensors, actuators, kinematics, and integrated system design.","difficulty":"Intermediate","category":"Part 1 - Foundations","keywords":["robotics hardware","sensors","actuators","control loops","kinematics","system integration","embodied intelligence"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 1: Physical AI Fundamentals","permalink":"/part-1/physical_ai_fundamentals"},"next":{"title":"Chapter 3: From Simulation to Reality (Sim2Real)","permalink":"/part-1/sim_to_reality"}},{"id":"part-1/sim_to_reality","title":"Chapter 3 - From Simulation to Reality (Sim2Real)","description":"The digital twin concept, the reality gap problem, domain randomization, and practical techniques for transferring trained policies and models from simulation to physical robots. Covers economic and engineering trade-offs.","source":"@site/docs/part-1/03_sim_to_reality.md","sourceDirName":"part-1","slug":"/part-1/sim_to_reality","permalink":"/part-1/sim_to_reality","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Chapter 3 - From Simulation to Reality (Sim2Real)","description":"The digital twin concept, the reality gap problem, domain randomization, and practical techniques for transferring trained policies and models from simulation to physical robots. Covers economic and engineering trade-offs.","difficulty":"Intermediate to Advanced","category":"Part 1 - Foundations","keywords":["simulation","digital twin","sim-to-real transfer","reality gap","domain randomization","physics engine","Gazebo","training data generation"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 2: Robotics Systems & Embodied Intelligence","permalink":"/part-1/robotics_systems"},"next":{"title":"Part 2 Overview","permalink":"/part-2/PART_2_overview"}},{"id":"part-2/agent_ros_communication","title":"Chapter 7 - Agent-to-ROS Communication Patterns","description":"Integration of AI agents (learned policies, planners, decision systems) with ROS 2 communication layer, addressing latency, failure modes, and real-time constraints.","source":"@site/docs/part-2/07_agent_ros_communication.md","sourceDirName":"part-2","slug":"/part-2/agent_ros_communication","permalink":"/part-2/agent_ros_communication","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"title":"Chapter 7 - Agent-to-ROS Communication Patterns","description":"Integration of AI agents (learned policies, planners, decision systems) with ROS 2 communication layer, addressing latency, failure modes, and real-time constraints.","difficulty":"Advanced","category":"Part 2 - ROS 2","keywords":["AI agents","policies","planning","ROS 2 integration","latency","real-time","safety","perception-action loops"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 6: Python-Based ROS 2 Development with rclpy","permalink":"/part-2/python_ros2_development"},"next":{"title":"Chapter 8: URDF and Robot Description for Humanoids","permalink":"/part-2/urdf_robot_description"}},{"id":"part-2/nodes_topics_services_actions","title":"Chapter 5 - Nodes, Topics, Services, and Actions","description":"Deep dive into ROS 2's core communication abstractions, practical patterns, design decisions, and failure modes for distributed robotics systems.","source":"@site/docs/part-2/05_nodes_topics_services_actions.md","sourceDirName":"part-2","slug":"/part-2/nodes_topics_services_actions","permalink":"/part-2/nodes_topics_services_actions","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Chapter 5 - Nodes, Topics, Services, and Actions","description":"Deep dive into ROS 2's core communication abstractions, practical patterns, design decisions, and failure modes for distributed robotics systems.","difficulty":"Intermediate","category":"Part 2 - ROS 2","keywords":["nodes","topics","services","actions","communication patterns","design","callbacks","subscriptions"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 4: ROS 2 Architecture & Middleware","permalink":"/part-2/ros2_architecture"},"next":{"title":"Chapter 6: Python-Based ROS 2 Development with rclpy","permalink":"/part-2/python_ros2_development"}},{"id":"part-2/PART_2_overview","title":"PART 2 - ROS 2 - The Robotic Nervous System","description":"Overview of Part 2, covering ROS 2 architecture, node communication patterns, Python development, agent integration, and robot description languages.","source":"@site/docs/part-2/PART_2_overview.md","sourceDirName":"part-2","slug":"/part-2/PART_2_overview","permalink":"/part-2/PART_2_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 2 - ROS 2 - The Robotic Nervous System","description":"Overview of Part 2, covering ROS 2 architecture, node communication patterns, Python development, agent integration, and robot description languages.","difficulty":"Intermediate to Advanced","category":"Part 2 - ROS 2","keywords":["ROS 2","middleware","nodes","topics","services","actions","Python","URDF","humanoid","communication"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 3: From Simulation to Reality (Sim2Real)","permalink":"/part-1/sim_to_reality"},"next":{"title":"Chapter 4: ROS 2 Architecture & Middleware","permalink":"/part-2/ros2_architecture"}},{"id":"part-2/python_ros2_development","title":"Chapter 6 - Python-Based ROS 2 Development with rclpy","description":"Practical guide to writing production-quality ROS 2 nodes in Python using rclpy, including initialization, spin loops, threading models, parameters, and safe shutdown.","source":"@site/docs/part-2/06_python_ros2_development.md","sourceDirName":"part-2","slug":"/part-2/python_ros2_development","permalink":"/part-2/python_ros2_development","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"Chapter 6 - Python-Based ROS 2 Development with rclpy","description":"Practical guide to writing production-quality ROS 2 nodes in Python using rclpy, including initialization, spin loops, threading models, parameters, and safe shutdown.","difficulty":"Intermediate","category":"Part 2 - ROS 2","keywords":["Python","rclpy","ROS 2 development","nodes","callbacks","threading","parameters","lifecycle"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 5: Nodes, Topics, Services, and Actions","permalink":"/part-2/nodes_topics_services_actions"},"next":{"title":"Chapter 7: Agent-to-ROS Communication Patterns","permalink":"/part-2/agent_ros_communication"}},{"id":"part-2/ros2_architecture","title":"Chapter 4 - ROS 2 Architecture and Middleware","description":"Comprehensive overview of ROS 2 architecture, middleware, publish/subscribe patterns, services, actions, QoS, and design principles for distributed robotics systems.","source":"@site/docs/part-2/04_ros2_architecture.md","sourceDirName":"part-2","slug":"/part-2/ros2_architecture","permalink":"/part-2/ros2_architecture","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Chapter 4 - ROS 2 Architecture and Middleware","description":"Comprehensive overview of ROS 2 architecture, middleware, publish/subscribe patterns, services, actions, QoS, and design principles for distributed robotics systems.","difficulty":"Intermediate","category":"Part 2 - ROS 2","keywords":["ROS 2","middleware","architecture","publish/subscribe","DDS","QoS","services","actions","distributed systems"]},"sidebar":"textbookSidebar","previous":{"title":"Part 2 Overview","permalink":"/part-2/PART_2_overview"},"next":{"title":"Chapter 5: Nodes, Topics, Services, and Actions","permalink":"/part-2/nodes_topics_services_actions"}},{"id":"part-2/urdf_robot_description","title":"Chapter 8 - URDF and Robot Description for Humanoids","description":"Complete guide to describing robot kinematics, dynamics, and geometry using URDF, with focus on humanoid robots and ROS 2 integration.","source":"@site/docs/part-2/08_urdf_robot_description.md","sourceDirName":"part-2","slug":"/part-2/urdf_robot_description","permalink":"/part-2/urdf_robot_description","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"title":"Chapter 8 - URDF and Robot Description for Humanoids","description":"Complete guide to describing robot kinematics, dynamics, and geometry using URDF, with focus on humanoid robots and ROS 2 integration.","difficulty":"Intermediate","category":"Part 2 - ROS 2","keywords":["URDF","robot description","kinematics","collision geometry","humanoid","TF","visualization","rviz2"]},"sidebar":"textbookSidebar","previous":{"title":"Chapter 7: Agent-to-ROS Communication Patterns","permalink":"/part-2/agent_ros_communication"},"next":{"title":"Part 3 Overview","permalink":"/part-3/PART_3_overview"}},{"id":"part-3/PART_3_overview","title":"PART 3 Overview","description":"Digital Twin & Simulation - Coming Soon","source":"@site/docs/part-3/PART_3_overview.md","sourceDirName":"part-3","slug":"/part-3/PART_3_overview","permalink":"/part-3/PART_3_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 3 Overview","description":"Digital Twin & Simulation - Coming Soon"},"sidebar":"textbookSidebar","previous":{"title":"Chapter 8: URDF and Robot Description for Humanoids","permalink":"/part-2/urdf_robot_description"},"next":{"title":"Part 4 Overview","permalink":"/part-4/PART_4_overview"}},{"id":"part-4/PART_4_overview","title":"PART 4 Overview","description":"NVIDIA Isaac - The AI Robot Brain - Coming Soon","source":"@site/docs/part-4/PART_4_overview.md","sourceDirName":"part-4","slug":"/part-4/PART_4_overview","permalink":"/part-4/PART_4_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 4 Overview","description":"NVIDIA Isaac - The AI Robot Brain - Coming Soon"},"sidebar":"textbookSidebar","previous":{"title":"Part 3 Overview","permalink":"/part-3/PART_3_overview"},"next":{"title":"Part 5 Overview","permalink":"/part-5/PART_5_overview"}},{"id":"part-5/PART_5_overview","title":"PART 5 Overview","description":"Vision-Language-Action (VLA) - Coming Soon","source":"@site/docs/part-5/PART_5_overview.md","sourceDirName":"part-5","slug":"/part-5/PART_5_overview","permalink":"/part-5/PART_5_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 5 Overview","description":"Vision-Language-Action (VLA) - Coming Soon"},"sidebar":"textbookSidebar","previous":{"title":"Part 4 Overview","permalink":"/part-4/PART_4_overview"},"next":{"title":"Part 6 Overview","permalink":"/part-6/PART_6_overview"}},{"id":"part-6/PART_6_overview","title":"PART 6 Overview","description":"Conversational Humanoid Robots - Coming Soon","source":"@site/docs/part-6/PART_6_overview.md","sourceDirName":"part-6","slug":"/part-6/PART_6_overview","permalink":"/part-6/PART_6_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 6 Overview","description":"Conversational Humanoid Robots - Coming Soon"},"sidebar":"textbookSidebar","previous":{"title":"Part 5 Overview","permalink":"/part-5/PART_5_overview"},"next":{"title":"Part 7 Overview","permalink":"/part-7/PART_7_overview"}},{"id":"part-7/PART_7_overview","title":"PART 7 Overview","description":"Capstone - Autonomous Humanoid System - Coming Soon","source":"@site/docs/part-7/PART_7_overview.md","sourceDirName":"part-7","slug":"/part-7/PART_7_overview","permalink":"/part-7/PART_7_overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"PART 7 Overview","description":"Capstone - Autonomous Humanoid System - Coming Soon"},"sidebar":"textbookSidebar","previous":{"title":"Part 6 Overview","permalink":"/part-6/PART_6_overview"},"next":{"title":"Technical Glossary","permalink":"/glossary"}},{"id":"rag_index","title":"RAG Index & Semantic Search Map","description":"AI-Native Physical AI & Humanoid Robotics Textbook","source":"@site/docs/rag_index.md","sourceDirName":".","slug":"/rag_index","permalink":"/rag_index","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Technical Glossary","permalink":"/glossary"},"next":{"title":"Additional Resources","permalink":"/resources"}},{"id":"resources","title":"Additional Resources","description":"Recommended reading, tools, communities, and external resources for Physical AI and robotics","source":"@site/docs/resources.md","sourceDirName":".","slug":"/resources","permalink":"/resources","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Additional Resources","description":"Recommended reading, tools, communities, and external resources for Physical AI and robotics"},"sidebar":"textbookSidebar","previous":{"title":"RAG Index & Semantic Map","permalink":"/rag_index"}},{"id":"UI_COMPONENTS_SHOWCASE","title":"Professional UI Components Showcase","description":"Examples of all professional UI components and hover effects","source":"@site/docs/UI_COMPONENTS_SHOWCASE.md","sourceDirName":".","slug":"/UI_COMPONENTS_SHOWCASE","permalink":"/UI_COMPONENTS_SHOWCASE","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Professional UI Components Showcase","description":"Examples of all professional UI components and hover effects"}}],"drafts":[],"sidebars":{"textbookSidebar":[{"type":"doc","id":"introduction","label":"Book Introduction","translatable":true},{"type":"category","label":"PART 1: Foundations of Physical AI","collapsed":false,"items":[{"type":"doc","id":"part-1/PART_1_overview","label":"Part 1 Overview","translatable":true},{"type":"doc","id":"part-1/physical_ai_fundamentals","label":"Chapter 1: Physical AI Fundamentals","translatable":true},{"type":"doc","id":"part-1/robotics_systems","label":"Chapter 2: Robotics Systems & Embodied Intelligence","translatable":true},{"type":"doc","id":"part-1/sim_to_reality","label":"Chapter 3: From Simulation to Reality (Sim2Real)","translatable":true}],"collapsible":true},{"type":"category","label":"PART 2: ROS 2 – The Robotic Nervous System","collapsed":false,"items":[{"type":"doc","id":"part-2/PART_2_overview","label":"Part 2 Overview","translatable":true},{"type":"doc","id":"part-2/ros2_architecture","label":"Chapter 4: ROS 2 Architecture & Middleware","translatable":true},{"type":"doc","id":"part-2/nodes_topics_services_actions","label":"Chapter 5: Nodes, Topics, Services, and Actions","translatable":true},{"type":"doc","id":"part-2/python_ros2_development","label":"Chapter 6: Python-Based ROS 2 Development with rclpy","translatable":true},{"type":"doc","id":"part-2/agent_ros_communication","label":"Chapter 7: Agent-to-ROS Communication Patterns","translatable":true},{"type":"doc","id":"part-2/urdf_robot_description","label":"Chapter 8: URDF and Robot Description for Humanoids","translatable":true}],"collapsible":true},{"type":"category","label":"PART 3: Digital Twin & Simulation","collapsed":true,"items":[{"type":"doc","id":"part-3/PART_3_overview","label":"Part 3 Overview","translatable":true}],"collapsible":true},{"type":"category","label":"PART 4: NVIDIA Isaac – The AI Robot Brain","collapsed":true,"items":[{"type":"doc","id":"part-4/PART_4_overview","label":"Part 4 Overview","translatable":true}],"collapsible":true},{"type":"category","label":"PART 5: Vision-Language-Action (VLA)","collapsed":true,"items":[{"type":"doc","id":"part-5/PART_5_overview","label":"Part 5 Overview","translatable":true}],"collapsible":true},{"type":"category","label":"PART 6: Conversational Humanoid Robots","collapsed":true,"items":[{"type":"doc","id":"part-6/PART_6_overview","label":"Part 6 Overview","translatable":true}],"collapsible":true},{"type":"category","label":"PART 7: Capstone – Autonomous Humanoid System","collapsed":true,"items":[{"type":"doc","id":"part-7/PART_7_overview","label":"Part 7 Overview","translatable":true}],"collapsible":true},{"type":"category","label":"Reference Materials","collapsed":false,"items":[{"type":"doc","id":"glossary","label":"Technical Glossary","translatable":true},{"type":"doc","id":"rag_index","label":"RAG Index & Semantic Map","translatable":true},{"type":"doc","id":"resources","label":"Additional Resources","translatable":true}],"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":null},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}